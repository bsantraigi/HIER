{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=-1\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import logging.handlers\n",
    "import os\n",
    "import random\n",
    "from collections import OrderedDict\n",
    "\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "from MultiWOZ import get_batch\n",
    "from evaluator import evaluateModel_Slow\n",
    "from tools import *\n",
    "from transformer.Transformer import RespGenerator, UncertaintyLoss\n",
    "from tqdm import tqdm\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(act_source='bert', batch_size=384, beam_size=2, data_dir='data', dropout=0.2, emb_dim=128, evaluate_every=5, head=4, hist_num=0, layer_num=3, learning_rate=0.001, log='log', max_seq_length=50, model='model/MarCo_BERT', ngram=3, non_delex=False, option='test', output_file='output', resume=False, seed=1)\n"
     ]
    }
   ],
   "source": [
    "def parse_opt():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--option', type=str, default=\"train\", help=\"whether to train or test the model\", choices=['train', 'test', 'postprocess'])\n",
    "    parser.add_argument('--emb_dim', type=int, default=128, help=\"the embedding dimension\")\n",
    "    parser.add_argument('--dropout', type=float, default=0.2, help=\"dropout rate\")\n",
    "    parser.add_argument('--resume', action='store_true', default=False, help=\"whether to resume previous run\")\n",
    "    parser.add_argument('--batch_size', type=int, default=3, help=\"train/dev/test batch size\")\n",
    "    parser.add_argument('--model', type=str, default=\"model\", help=\"path to save or load models\")\n",
    "    parser.add_argument('--data_dir', type=str, default='data', help=\"data dir\")\n",
    "    parser.add_argument('--beam_size', type=int, default=2, help=\"beam size of act/response generator\")\n",
    "    parser.add_argument('--max_seq_length', type=int, default=50, help=\"max input length\")\n",
    "    parser.add_argument('--ngram', type=int, default=3, help=\"avoid n gram repeatness\")\n",
    "    parser.add_argument('--layer_num', type=int, default=3, help=\"transformer layer num\")\n",
    "    parser.add_argument('--evaluate_every', type=int, default=5, help=\"checkpoints\")\n",
    "    parser.add_argument('--head', type=int, default=4, help=\"head num for transformer\")\n",
    "    parser.add_argument(\"--learning_rate\", default=1e-3, type=float, help=\"The initial learning rate for Adam.\")\n",
    "    parser.add_argument(\"--output_file\", default='output', type=str, help=\"path to save generated act/response\")\n",
    "    parser.add_argument(\"--non_delex\", default=False, action=\"store_true\", help=\"non delex testing\")\n",
    "    parser.add_argument(\"--hist_num\", default=0,type=int, help=\"turn num of history\")\n",
    "    parser.add_argument('--log', type=str, default='log', help=\"log file\")\n",
    "\n",
    "    parser.add_argument('--act_source',  type=str, choices=[\"pred\", \"bert\",'groundtruth'], default='pred', help=\"action source for validate/test\")\n",
    "    parser.add_argument('--seed', type=int, default=1, help=\"random seed for initialization\")\n",
    "\n",
    "    args = parser.parse_args(\"--option test --model model/MarCo_BERT --batch_size 384 --max_seq_length 50 --act_source bert\".split())\n",
    "    return args\n",
    "\n",
    "args = parse_opt()\n",
    "print(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.option == 'train':\n",
    "    if not os.path.exists(args.model):\n",
    "        os.makedirs(args.model)\n",
    "    args.log = os.path.join(args.model, 'train.log')\n",
    "elif args.option == 'test':\n",
    "    dir = os.path.dirname(args.model)\n",
    "    args.log = os.path.join(dir, 'test.log')\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "handler1 = logging.StreamHandler()\n",
    "handler2 = logging.FileHandler(filename=args.log)\n",
    "\n",
    "logger.setLevel(logging.DEBUG)\n",
    "handler1.setLevel(logging.WARNING)\n",
    "handler2.setLevel(logging.DEBUG)\n",
    "\n",
    "formatter = logging.Formatter(\"%(asctime)s %(name)s %(levelname)s %(message)s\")\n",
    "handler1.setFormatter(formatter)\n",
    "handler2.setFormatter(formatter)\n",
    "\n",
    "logger.addHandler(handler1)\n",
    "logger.addHandler(handler2)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def setup_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    numpy.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "setup_seed(args.seed)\n",
    "\n",
    "with open(\"{}/vocab.json\".format(args.data_dir), 'r') as f:\n",
    "    vocabulary = json.load(f)\n",
    "\n",
    "act_ontology = Constants.act_ontology\n",
    "\n",
    "vocab, ivocab = vocabulary['vocab'], vocabulary['rev']\n",
    "tokenizer = Tokenizer(vocab, ivocab, False)\n",
    "\n",
    "with open(\"{}/act_vocab.json\".format(args.data_dir), 'r') as f:\n",
    "    act_vocabulary = json.load(f)\n",
    "\n",
    "act_vocab, act_ivocab = act_vocabulary['vocab'], act_vocabulary['rev']\n",
    "act_tokenizer = Tokenizer(act_vocab, act_ivocab, False)\n",
    "\n",
    "logger.info(\"Loading Vocabulary of {} size\".format(tokenizer.vocab_len))\n",
    "# Loading the dataset\n",
    "\n",
    "checkpoint_file = args.model\n",
    "\n",
    "if 'train' in args.option:\n",
    "    *train_examples, _ = get_batch(args.data_dir, 'train', tokenizer, act_tokenizer, args.max_seq_length)\n",
    "    train_data = TensorDataset(*train_examples)\n",
    "    train_sampler = RandomSampler(train_data)\n",
    "    train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=args.batch_size)\n",
    "    *val_examples, val_id = get_batch(args.data_dir, 'val', tokenizer, act_tokenizer, args.max_seq_length)\n",
    "    dialogs = json.load(open('{}/val.json'.format(args.data_dir)))\n",
    "    gt_turns = json.load(open('{}/val_reference.json'.format(args.data_dir)))\n",
    "elif 'test' in args.option or 'postprocess' in args.option:\n",
    "    *val_examples, val_id = get_batch(args.data_dir, 'test', tokenizer, act_tokenizer, args.max_seq_length)\n",
    "    dialogs = json.load(open('{}/test.json'.format(args.data_dir)))\n",
    "    if args.non_delex:\n",
    "        gt_turns = json.load(open('{}/test_reference_nondelex.json'.format(args.data_dir)))\n",
    "    else:\n",
    "        gt_turns = json.load(open('{}/test_reference.json'.format(args.data_dir)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_data = TensorDataset(*val_examples)\n",
    "eval_sampler = SequentialSampler(eval_data)\n",
    "eval_dataloader = DataLoader(eval_data, sampler=eval_sampler, batch_size=args.batch_size)\n",
    "\n",
    "BLEU_calc = BLEUScorer()\n",
    "F1_calc = F1Scorer()\n",
    "\n",
    "best_BLEU = 0\n",
    "\n",
    "weighted_loss_func = UncertaintyLoss(2)\n",
    "weighted_loss_func.to(device)\n",
    "\n",
    "resp_generator = RespGenerator(vocab_size=tokenizer.vocab_len,\n",
    "                               act_vocab_size=act_tokenizer.vocab_len,\n",
    "                               d_word_vec=args.emb_dim,\n",
    "                               act_dim=Constants.act_len,\n",
    "                               n_layers=args.layer_num,\n",
    "                               d_model=args.emb_dim,\n",
    "                               n_head=args.head,\n",
    "                               dropout=args.dropout)\n",
    "\n",
    "resp_generator.to(device)\n",
    "\n",
    "bce_loss_func = torch.nn.BCEWithLogitsLoss()\n",
    "bce_loss_func.to(device)\n",
    "\n",
    "ce_loss_func = torch.nn.CrossEntropyLoss(ignore_index=Constants.PAD)\n",
    "ce_loss_func.to(device)\n",
    "\n",
    "\n",
    "label_list = Constants.functions + Constants.arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp_generator.load_state_dict(torch.load(args.model, map_location=device))\n",
    "resp_generator.eval()\n",
    "logger.info(\"Loading model from {}\".format(checkpoint_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [00:00<?, ?it/s]/opt/conda/conda-bld/pytorch_1587428398394/work/aten/src/ATen/native/BinaryOps.cpp:81: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead.\n",
      "100%|██████████| 20/20 [15:28<00:00, 46.45s/it]\n"
     ]
    }
   ],
   "source": [
    "# Start Evaluating after each epoch\n",
    "model_turns = {}\n",
    "act_turns={}\n",
    "context_inputs = {}\n",
    "TP, TN, FN, FP = 0, 0, 0, 0\n",
    "example_success={}\n",
    "for batch_step, batch in tqdm(enumerate(eval_dataloader), total=len(eval_dataloader)):\n",
    "    all_pred = []\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "    input_ids, action_masks, rep_in, resp_out, belief_state, bert_act_seq, act_in, act_out, all_label, \\\n",
    "    act_input_mask, resp_input_mask, *_ = batch\n",
    "\n",
    "    if args.act_source == 'bert':\n",
    "        act_in = bert_act_seq\n",
    "    elif args.act_source == 'pred':\n",
    "        hyps, act_logits = resp_generator.act_translate_batch(input_mask=act_input_mask, bs=belief_state, \\\n",
    "                                                              src_seq=input_ids, n_bm=args.beam_size,\n",
    "                                                              max_token_seq_len=Constants.ACT_MAX_LEN)\n",
    "        for hyp_step, hyp in enumerate(hyps):\n",
    "            pre1 = [0] * Constants.act_len\n",
    "            for w in hyp:\n",
    "                if w not in [Constants.PAD, Constants.EOS]:\n",
    "                    pre1[w - 3] = 1\n",
    "            if len(hyp) < Constants.ACT_MAX_LEN:\n",
    "                hyps[hyp_step] = list(hyps[hyp_step]) + [Constants.PAD] * (Constants.ACT_MAX_LEN - len(hyp))\n",
    "            all_pred.append(pre1)\n",
    "            file_name = val_id[batch_step * args.batch_size + hyp_step]\n",
    "            if file_name not in act_turns:\n",
    "                act_turns[file_name] = [pre1]\n",
    "            else:\n",
    "                act_turns[file_name].append(pre1)\n",
    "\n",
    "        all_pred=torch.Tensor(all_pred)\n",
    "        all_label=all_label.cpu()\n",
    "        TP, TN, FN, FP = obtain_TP_TN_FN_FP(all_pred, all_label, TP, TN, FN, FP)\n",
    "\n",
    "        act_in = torch.tensor(hyps, dtype=torch.long).to(device)\n",
    "    else:\n",
    "        pass\n",
    "    _, _, act_vecs = resp_generator.act_forward(tgt_seq=act_in, src_seq=input_ids, bs=belief_state,\n",
    "                                                input_mask=act_input_mask)\n",
    "    action_masks = act_in.eq(Constants.PAD) + act_in.eq(Constants.EOS)\n",
    "    resp_hyps = resp_generator.resp_translate_batch(bs=belief_state, act_vecs=act_vecs, act_mask=action_masks,\n",
    "                                                    input_mask=resp_input_mask,\n",
    "                                                    src_seq=input_ids, n_bm=args.beam_size,\n",
    "                                                    max_token_seq_len=40,gram_num=args.ngram)\n",
    "\n",
    "    for hyp_step, hyp in enumerate(resp_hyps):\n",
    "        pred = tokenizer.convert_id_to_tokens(hyp)\n",
    "        file_name = val_id[batch_step * args.batch_size + hyp_step]\n",
    "        if file_name not in model_turns:\n",
    "            model_turns[file_name] = [pred]\n",
    "        else:\n",
    "            model_turns[file_name].append(pred)\n",
    "            \n",
    "        context = tokenizer.convert_id_to_tokens(batch[0][hyp_step])\n",
    "        if file_name not in context_inputs:\n",
    "            context_inputs[file_name] = [context]\n",
    "        else:\n",
    "            context_inputs[file_name].append(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACT precision is 0.000000 recall is 0.000000 F1 is 0.000000\n",
      "Corpus Inform Success : 92.30%\n",
      "Corpus Requestable Success : 78.60%\n",
      "Test BLEU 0.2003, inform 92.30, request 78.60, score 105.48\n",
      "Test Entity-F1 59.9920\n"
     ]
    }
   ],
   "source": [
    "precision = TP / (TP + FP + 0.001)\n",
    "recall = TP / (TP + FN + 0.001)\n",
    "F1 = 2 * precision * recall / (precision + recall + 0.001)\n",
    "print(\"ACT precision is {:.6f} recall is {:.6f} F1 is {:.6f}\".format(precision, recall, F1))\n",
    "logger.info(\"ACT precision is {:.6f} recall is {:.6f} F1 is {:.6f}\".format(precision, recall, F1))\n",
    "\n",
    "BLEU = BLEU_calc.score(model_turns, gt_turns)\n",
    "inform, request, all_match_success = evaluateModel_Slow(model_turns, example_success)\n",
    "print(\"Test BLEU {:.4f}, inform {:.2f}, request {:.2f}, score {:.2f}\".format(BLEU, inform, request, (inform + request) / 2 + 100 * BLEU))\n",
    "logger.info(\"Test BLEU {:.4f}, inform {:.2f}, request {:.2f}, score {:.2f}\".format(BLEU, inform, request, (inform + request) / 2 + 100 * BLEU))\n",
    "\n",
    "# Match and Success stats\n",
    "pred_file = os.path.join(args.output_file, 'stats_pred'+'.tsv')\n",
    "all_match_success = [{\n",
    "    'file': f,\n",
    "    'match': m,\n",
    "    'success': s\n",
    "} for f,(m,s) in all_match_success.items()]\n",
    "all_match_success = pd.DataFrame.from_records(all_match_success)\n",
    "all_match_success.to_csv(pred_file, sep=\"\\t\", index=False)\n",
    "\n",
    "f1_entity = F1_calc.score(model_turns, gt_turns)*100\n",
    "print(\"Test Entity-F1 {:.4f}\".format(f1_entity))\n",
    "logger.info(\"Test Entity-F1 {:.4f}\".format(f1_entity))\n",
    "\n",
    "resp_file = os.path.join(args.output_file, 'resp_pred.json')\n",
    "with open(resp_file, 'w') as fp:\n",
    "    model_turns = OrderedDict(sorted(model_turns.items()))\n",
    "    json.dump(model_turns, fp, indent=2)\n",
    "\n",
    "act_file = os.path.join(args.output_file, 'act_pred.json')\n",
    "with open(act_file, 'w') as fp:\n",
    "    act_turns = OrderedDict(sorted(act_turns.items()))\n",
    "    json.dump(act_turns, fp, indent=2)\n",
    "\n",
    "with open('output/example_statistic.json','w') as f:\n",
    "    json.dump(example_success,f)\n",
    "\n",
    "save_name = 'test-inform-{:.2f}-request-{:.2f}-bleu-{:.4f}'.format(inform, request, BLEU)\n",
    "torch.save(resp_generator.state_dict(), os.path.join('model', save_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = []\n",
    "for key, preds in model_turns.items():\n",
    "    for i, t in enumerate(preds):\n",
    "        if t is None:\n",
    "            raise Exception(t)\n",
    "        bleu = BLEU_calc.score({key: [t]}, {key: [gt_turns[key][i]]})*100\n",
    "        f1 = F1_calc.score({key: [t]}, {key: [gt_turns[key][i]]})*100\n",
    "        df.append({\n",
    "            'file': key,\n",
    "            'context': context_inputs[key][i].replace('[SEP]', '<br>'),\n",
    "            'gold': gt_turns[key][i],\n",
    "            # There are some empty string predictions\n",
    "            'generated': t if len(t) > 0 else \" \",\n",
    "            'loss': 0,\n",
    "            'bleu': bleu,\n",
    "            'f1_entity': f1,\n",
    "            'context_length': 2*i+1 # last user + 2*i{usr,sys}\n",
    "        })\n",
    "#     pred_file.write(f\"file\\tcontext\\tgold\\tgenerated\\tloss\\tbleu\\tf1_entity\\n\")\n",
    "#     for idx, h, r, l, b, f1, file in tqdm(zip(indices, pred_hyp, pred_ref, losses, bleus, f1_ents, all_dialog_files)):\n",
    "#         pred_file.write(f\"{file}\\t{'<br>'.join(data[idx][:-1])}\\t{str(r)}\\t{str(h)}\\t{str(l)}\\t{str(b)}\\t{str(f1)}\\n\")\n",
    "\n",
    "df = pd.DataFrame.from_records(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>context</th>\n",
       "      <th>gold</th>\n",
       "      <th>generated</th>\n",
       "      <th>loss</th>\n",
       "      <th>bleu</th>\n",
       "      <th>f1_entity</th>\n",
       "      <th>context_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4506</th>\n",
       "      <td>PMUL2578</td>\n",
       "      <td>number is [hotel_phone] &lt;br&gt; i would also like...</td>\n",
       "      <td>where are you departing from ? what is your de...</td>\n",
       "      <td>i would be happy to book a taxi for you . wher...</td>\n",
       "      <td>0</td>\n",
       "      <td>34.892157</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4498</th>\n",
       "      <td>PMUL2563</td>\n",
       "      <td>name type [UNK] id postcode reference area add...</td>\n",
       "      <td>thank you for contacting us , have a nice day .</td>\n",
       "      <td>you are welcome , have a great day !</td>\n",
       "      <td>0</td>\n",
       "      <td>0.511282</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1162</th>\n",
       "      <td>MUL1028</td>\n",
       "      <td>. phone name type id area address postcode ref...</td>\n",
       "      <td>the phone number for [attraction_name] is [att...</td>\n",
       "      <td>the address for [attraction_name] is [attracti...</td>\n",
       "      <td>0</td>\n",
       "      <td>52.694553</td>\n",
       "      <td>79.920040</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6100</th>\n",
       "      <td>PMUL4644</td>\n",
       "      <td>. can you look again please ? phone name type ...</td>\n",
       "      <td>[hotel_name] is very nice .</td>\n",
       "      <td>how about [hotel_name] ? it s located at [hote...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.013194</td>\n",
       "      <td>66.577830</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2702</th>\n",
       "      <td>MUL2439</td>\n",
       "      <td>[restaurant_pricerange] price -s . postcode ty...</td>\n",
       "      <td>the address is [restaurant_address] . it is in...</td>\n",
       "      <td>[restaurant_name] is located in the [restauran...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.375536</td>\n",
       "      <td>74.934407</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1653</th>\n",
       "      <td>MUL1546</td>\n",
       "      <td>reference &lt;br&gt; it s booked and will cost [valu...</td>\n",
       "      <td>[restaurant_name] is an inexpensive [restauran...</td>\n",
       "      <td>[restaurant_name] is a [restaurant_food] resta...</td>\n",
       "      <td>0</td>\n",
       "      <td>26.773546</td>\n",
       "      <td>74.934407</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          file                                            context  \\\n",
       "4506  PMUL2578  number is [hotel_phone] <br> i would also like...   \n",
       "4498  PMUL2563  name type [UNK] id postcode reference area add...   \n",
       "1162   MUL1028  . phone name type id area address postcode ref...   \n",
       "6100  PMUL4644  . can you look again please ? phone name type ...   \n",
       "2702   MUL2439  [restaurant_pricerange] price -s . postcode ty...   \n",
       "1653   MUL1546  reference <br> it s booked and will cost [valu...   \n",
       "\n",
       "                                                   gold  \\\n",
       "4506  where are you departing from ? what is your de...   \n",
       "4498    thank you for contacting us , have a nice day .   \n",
       "1162  the phone number for [attraction_name] is [att...   \n",
       "6100                        [hotel_name] is very nice .   \n",
       "2702  the address is [restaurant_address] . it is in...   \n",
       "1653  [restaurant_name] is an inexpensive [restauran...   \n",
       "\n",
       "                                              generated  loss       bleu  \\\n",
       "4506  i would be happy to book a taxi for you . wher...     0  34.892157   \n",
       "4498               you are welcome , have a great day !     0   0.511282   \n",
       "1162  the address for [attraction_name] is [attracti...     0  52.694553   \n",
       "6100  how about [hotel_name] ? it s located at [hote...     0   0.013194   \n",
       "2702  [restaurant_name] is located in the [restauran...     0   0.375536   \n",
       "1653  [restaurant_name] is a [restaurant_food] resta...     0  26.773546   \n",
       "\n",
       "      f1_entity  context_length  \n",
       "4506   0.000000              15  \n",
       "4498   0.000000              11  \n",
       "1162  79.920040               9  \n",
       "6100  66.577830               5  \n",
       "2702  74.934407               7  \n",
       "1653  74.934407               7  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('output/error_beam_test.tsv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1522129258452236\n"
     ]
    }
   ],
   "source": [
    "resp_file = os.path.join(args.output_file, 'resp_pred.json')\n",
    "with open(resp_file, 'r') as f:\n",
    "    model_turns = json.load(f)\n",
    "\n",
    "success_rate = nondetokenize(model_turns, dialogs)\n",
    "BLEU = BLEU_calc.score(model_turns, gt_turns)\n",
    "print(BLEU)\n",
    "\n",
    "resp_file = os.path.join(args.output_file, 'resp_non_delex_pred.json')\n",
    "with open(resp_file, 'w') as fp:\n",
    "    model_turns = OrderedDict(sorted(model_turns.items()))\n",
    "    json.dump(model_turns, fp, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Marco-BERT\n",
    "\n",
    "```\n",
    "ACT precision is 0.000000 recall is 0.000000 F1 is 0.000000\n",
    "Corpus Inform Success : 92.30%\n",
    "Corpus Requestable Success : 78.60%\n",
    "Test BLEU 0.2003, inform 92.30, request 78.60, score 105.48\n",
    "Test F1-Entity 59.9920\n",
    "```\n",
    "\n",
    "### Marco-PredAct\n",
    "\n",
    "```\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
